{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('trivy-results-15.json', 'Trivy.txt', 'ONOS')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"trivy-results-15.json\", \"Trivy.txt\", \"ONOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snyk: Skipping:onos-a1t/test/utils/xapp/go.mod\n",
      "Snyk: Skipping:onos-config/benchmark/go.mod\n",
      "Snyk: Skipping:onos-config/test/go.mod\n",
      "Snyk: Skipping:onos-e2t/test/go.mod\n",
      "Snyk: Skipping:onos-topo/test/go.mod\n",
      "Snyk: Skipping:onos-a1t/test/utils/xapp/go.mod\n",
      "Snyk: Skipping:onos-config/benchmark/go.mod\n",
      "Snyk: Skipping:onos-config/test/go.mod\n",
      "Snyk: Skipping:onos-e2t/test/go.mod\n",
      "Snyk: Skipping:onos-topo/test/go.mod\n",
      "Finished writing: 'sca_results.json'\n",
      "Finished reading the SCA results data.\n",
      "onos-a1t\n",
      "onos-cli\n",
      "onos-config\n",
      "onos-e2t\n",
      "onos-kpimon\n",
      "onos-lib-go\n",
      "onos-operator\n",
      "onos-topo\n",
      "onos-uenib\n",
      "Going to count CVEs per repo and per RIC\n",
      "RIC: ONOS, Repository: onos-a1t, Total Repo CVEs: 14\n",
      "RIC: ONOS, Repository: onos-cli, Total Repo CVEs: 4\n",
      "RIC: ONOS, Repository: onos-config, Total Repo CVEs: 4\n",
      "RIC: ONOS, Repository: onos-e2t, Total Repo CVEs: 6\n",
      "RIC: ONOS, Repository: onos-kpimon, Total Repo CVEs: 14\n",
      "RIC: ONOS, Repository: onos-lib-go, Total Repo CVEs: 0\n",
      "RIC: ONOS, Repository: onos-operator, Total Repo CVEs: 2\n",
      "RIC: ONOS, Repository: onos-topo, Total Repo CVEs: 4\n",
      "RIC: ONOS, Repository: onos-uenib, Total Repo CVEs: 13\n",
      "{'ONOS': ['CVE-2021-41190',\n",
      "          'CVE-2023-2253',\n",
      "          'CVE-2022-40083',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2023-39325',\n",
      "          'CVE-2023-45288',\n",
      "          'CVE-2024-24786',\n",
      "          'CVE-2023-25165',\n",
      "          'CVE-2024-25620',\n",
      "          'CVE-2022-23526',\n",
      "          'CVE-2024-26147',\n",
      "          'CVE-2022-23525',\n",
      "          'CVE-2022-36055',\n",
      "          'CVE-2022-23524',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2023-39325',\n",
      "          'CVE-2023-45288',\n",
      "          'CVE-2024-24786',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2023-39325',\n",
      "          'CVE-2023-45288',\n",
      "          'CVE-2024-24786',\n",
      "          'CVE-2023-52728',\n",
      "          'CVE-2023-52727',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2023-39325',\n",
      "          'CVE-2023-45288',\n",
      "          'CVE-2024-24786',\n",
      "          'CVE-2021-41190',\n",
      "          'CVE-2023-2253',\n",
      "          'CVE-2023-52726',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2023-39325',\n",
      "          'CVE-2023-45288',\n",
      "          'CVE-2024-24786',\n",
      "          'CVE-2023-25165',\n",
      "          'CVE-2024-25620',\n",
      "          'CVE-2022-23526',\n",
      "          'CVE-2024-26147',\n",
      "          'CVE-2022-23525',\n",
      "          'CVE-2022-36055',\n",
      "          'CVE-2022-23524',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2022-28948',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2023-39325',\n",
      "          'CVE-2023-45288',\n",
      "          'CVE-2024-24786',\n",
      "          'CVE-2021-41190',\n",
      "          'CVE-2023-2253',\n",
      "          'CVE-2023-44487',\n",
      "          'CVE-2023-39325',\n",
      "          'CVE-2023-45288',\n",
      "          'CVE-2024-24786',\n",
      "          'CVE-2023-25165',\n",
      "          'CVE-2024-25620',\n",
      "          'CVE-2022-23526',\n",
      "          'CVE-2024-26147',\n",
      "          'CVE-2022-23525',\n",
      "          'CVE-2022-36055',\n",
      "          'CVE-2022-23524']}\n",
      "RIC: ONOS, Total unique CVEs: 61\n",
      "1. CVEs per RIC/repo/tool\n",
      "2. Total CVEs per RIC/repo with duplicates\n",
      "3. Total CVEs per RIC/repo without duplicates\n",
      "Nonecounter: 0\n",
      "Analyzing package distribution...\n",
      "RIC: ONOS TOTAL Low CVEs: 3\n",
      "RIC: ONOS TOTAL Medium CVEs: 34\n",
      "RIC: ONOS TOTAL High CVEs: 24\n",
      "RIC: ONOS TOTAL Critical CVEs: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 716\u001b[0m\n\u001b[1;32m    713\u001b[0m         plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 716\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msnyk_results-9.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSnyk.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mONOS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 639\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_file, tool, ric)\u001b[0m\n\u001b[1;32m    636\u001b[0m vulnerable_packages_per_repo \u001b[38;5;241m=\u001b[39m {ric: {repo: packages_info[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_packages\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m repo, packages_info \u001b[38;5;129;01min\u001b[39;00m repos\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m ric, repos \u001b[38;5;129;01min\u001b[39;00m packages_per_ric_repo\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# Calculate total vulnerabilities per RIC\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m total_vulnerabilities_ric \u001b[38;5;241m=\u001b[39m {ric: \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vuln_list[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m vuln_list \u001b[38;5;129;01min\u001b[39;00m cve_per_ric_repo[ric]\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mfor\u001b[39;00m ric \u001b[38;5;129;01min\u001b[39;00m cve_per_ric_repo\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m# Remove the .txt extension from the tool name\u001b[39;00m\n\u001b[1;32m    642\u001b[0m tool_name \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[57], line 639\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    636\u001b[0m vulnerable_packages_per_repo \u001b[38;5;241m=\u001b[39m {ric: {repo: packages_info[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_packages\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m repo, packages_info \u001b[38;5;129;01min\u001b[39;00m repos\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m ric, repos \u001b[38;5;129;01min\u001b[39;00m packages_per_ric_repo\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# Calculate total vulnerabilities per RIC\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m total_vulnerabilities_ric \u001b[38;5;241m=\u001b[39m {ric: \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvuln_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvuln_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcve_per_ric_repo\u001b[49m\u001b[43m[\u001b[49m\u001b[43mric\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ric \u001b[38;5;129;01min\u001b[39;00m cve_per_ric_repo\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m# Remove the .txt extension from the tool name\u001b[39;00m\n\u001b[1;32m    642\u001b[0m tool_name \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[57], line 639\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    636\u001b[0m vulnerable_packages_per_repo \u001b[38;5;241m=\u001b[39m {ric: {repo: packages_info[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_packages\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m repo, packages_info \u001b[38;5;129;01min\u001b[39;00m repos\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m ric, repos \u001b[38;5;129;01min\u001b[39;00m packages_per_ric_repo\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# Calculate total vulnerabilities per RIC\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m total_vulnerabilities_ric \u001b[38;5;241m=\u001b[39m {ric: \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvuln_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m vuln_list \u001b[38;5;129;01min\u001b[39;00m cve_per_ric_repo[ric]\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mfor\u001b[39;00m ric \u001b[38;5;129;01min\u001b[39;00m cve_per_ric_repo\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[1;32m    641\u001b[0m \u001b[38;5;66;03m# Remove the .txt extension from the tool name\u001b[39;00m\n\u001b[1;32m    642\u001b[0m tool_name \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "import argparse\n",
    "from statistics import mean\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Tools used for SCA\n",
    "sca_tools = ['Grype.txt', 'Snyk.txt', 'Trivy.txt']\n",
    "\n",
    "# RICs (Radio Interface Controllers) to analyze\n",
    "rics = ['ONOS', 'OSC']\n",
    "\n",
    "# List to store repositories with errors\n",
    "repoWithError = []\n",
    "\n",
    "# Regular expressions to exclude certain packages in the RIC repositories\n",
    "test_package = re.compile(r'test/')\n",
    "benchmark_package = re.compile(r'benchmark')\n",
    "examples_package = re.compile(r'examples/')\n",
    "testapplication_package = re.compile(r'testapplication/')\n",
    "cert_package = re.compile(r'certs/')\n",
    "\n",
    "# Normalize the results from each tool\n",
    "def format_sca_tool_data(repository, tool):\n",
    "    if tool == \"Grype.txt\":\n",
    "        return formatGrype(repository)\n",
    "    elif tool == \"Snyk.txt\":\n",
    "        return formatSnyk(repository)\n",
    "    elif tool == \"Trivy.txt\":\n",
    "        return formatTrivy(repository)\n",
    "\n",
    "# Format the results from Grype tool\n",
    "def formatGrype(repository):\n",
    "    GrypeRepo = json.loads(repository)\n",
    "    vulnArray = []\n",
    "    for vuln in GrypeRepo[\"matches\"]:\n",
    "        path = vuln.get(\"artifact\").get(\"locations\")[0].get(\"path\")\n",
    "        if test_package.search(path) is not None:\n",
    "            continue\n",
    "        elif benchmark_package.search(path) is not None:\n",
    "            continue\n",
    "        elif examples_package.search(path) is not None:\n",
    "            continue\n",
    "        elif testapplication_package.search(path) is not None:\n",
    "            continue\n",
    "        else:\n",
    "            vulnArray.append(vuln)\n",
    "    return vulnArray\n",
    "\n",
    "# Format the results from Snyk tool\n",
    "def formatSnyk(repository):\n",
    "    content = json.loads(repository)\n",
    "    vulnArray = []\n",
    "    if \"error\" not in content:\n",
    "        for target in content:\n",
    "            if not isinstance(target, str):\n",
    "                vulnList = target.get('vulnerabilities')\n",
    "                path = target.get('displayTargetFile')\n",
    "                if test_package.search(path) is not None:\n",
    "                    print(\"Snyk: Skipping:\" + path)\n",
    "                    continue\n",
    "                elif benchmark_package.search(path) is not None:\n",
    "                    print(\"Snyk: Skipping:\" + path)\n",
    "                    continue\n",
    "                elif examples_package.search(path) is not None:\n",
    "                    print(\"Snyk: Skipping:\" + path)\n",
    "                    continue\n",
    "                elif testapplication_package.search(path) is not None:\n",
    "                    print(\"Snyk: Skipping:\" + path)\n",
    "                    continue\n",
    "                else:\n",
    "                    for vuln in vulnList:\n",
    "                        vuln.pop('semver')\n",
    "                        vulnArray.append(vuln)\n",
    "            else:\n",
    "                if target == 'vulnerabilities':\n",
    "                    vulnList = content.get('vulnerabilities')\n",
    "                    path = content.get('displayTargetFile')\n",
    "                    print(\"Snyk path: {}\".format(path))\n",
    "                    if test_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    elif benchmark_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    elif examples_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    elif testapplication_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    else:\n",
    "                        for vuln in vulnList:\n",
    "                            vuln.pop('semver')\n",
    "                            vulnArray.append(vuln)\n",
    "                            print(\"1\")\n",
    "    else:\n",
    "        global repoWithError\n",
    "        repoWithError.append(os.path.basename(content['path']))\n",
    "    return vulnArray\n",
    "\n",
    "# Format the results from Trivy tool\n",
    "def formatTrivy(repository):\n",
    "    index = repository.find(\"{\")\n",
    "    repo = repository[index:]\n",
    "    TrivyRepo = json.loads(repo)\n",
    "    results = TrivyRepo.get(\"Results\")\n",
    "    vulnArray = []\n",
    "    if results is not None:\n",
    "        for target in results:\n",
    "            path = target.get(\"Target\")\n",
    "            if test_package.search(path) is not None:\n",
    "                print(\"Trivy: Skipping:\" + path)\n",
    "                continue\n",
    "            elif benchmark_package.search(path) is not None:\n",
    "                print(\"Trivy: Skipping:\" + path)\n",
    "                continue\n",
    "            elif examples_package.search(path) is not None:\n",
    "                print(\"Trivy: Skipping:\" + path)\n",
    "                continue\n",
    "            else:\n",
    "                vulnTarget = target.get(\"Vulnerabilities\", [])\n",
    "                if not vulnTarget:\n",
    "                    continue\n",
    "                for vuln in vulnTarget:\n",
    "                    vuln[\"Path\"] = path\n",
    "                vulnArray.extend(vulnTarget)\n",
    "    return vulnArray\n",
    "\n",
    "# Get vulnerabilities categorized by directories\n",
    "def get_vulnerabilities_by_directory(data, tool):\n",
    "    # For Grype we can work with the formatted data directly\n",
    "    if tool == \"Grype.txt\":\n",
    "        formatted_data = format_sca_tool_data(data, \"Grype.txt\")\n",
    "    \n",
    "    # For Trivy we need to load the data into a JSON object first\n",
    "    elif tool == \"Trivy.txt\":\n",
    "        repo = json.loads(data)\n",
    "        results = repo.get(\"Results\")\n",
    "\n",
    "    # For Snyk we load the data as JSON\n",
    "    elif tool == \"Snyk.txt\":\n",
    "        content = json.loads(data)\n",
    "\n",
    "    vulnerabilities_by_directory = defaultdict(list)\n",
    "    \n",
    "    if tool == \"Grype.txt\":\n",
    "        for vuln in formatted_data:\n",
    "            path = vuln.get(\"artifact\").get(\"locations\")[0].get(\"path\")\n",
    "            directory = os.path.dirname(path)\n",
    "            vulnerabilities_by_directory[directory].append(vuln)\n",
    "        return vulnerabilities_by_directory\n",
    "    \n",
    "    elif tool == \"Trivy.txt\":\n",
    "        for vuln in results:\n",
    "            path = vuln.get(\"Target\")\n",
    "            if test_package.search(path) is not None:\n",
    "                continue\n",
    "            elif benchmark_package.search(path) is not None:\n",
    "                continue\n",
    "            elif examples_package.search(path) is not None:\n",
    "                continue\n",
    "            elif cert_package.search(path) is not None:\n",
    "                continue\n",
    "            else:\n",
    "                vulnTarget = vuln.get(\"Vulnerabilities\", [])\n",
    "                if not vulnTarget:\n",
    "                    continue\n",
    "                for vuln in vulnTarget:\n",
    "                    vuln[\"Path\"] = path\n",
    "                    directory = os.path.dirname(path)\n",
    "                    vulnerabilities_by_directory[directory].append(vuln)\n",
    "        return vulnerabilities_by_directory\n",
    "    \n",
    "    elif tool == \"Snyk.txt\":\n",
    "        if \"error\" not in content:\n",
    "            for target in content:\n",
    "                if not isinstance(target, str):\n",
    "                    vulnList = target.get('vulnerabilities')\n",
    "                    path = target.get('displayTargetFile')\n",
    "                    if test_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    elif benchmark_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    elif examples_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    elif testapplication_package.search(path) is not None:\n",
    "                        print(\"Snyk: Skipping:\" + path)\n",
    "                        continue\n",
    "                    else:\n",
    "                        for vuln in vulnList:\n",
    "                            directory = os.path.dirname(path)\n",
    "                            vulnerabilities_by_directory[directory].append(vuln)\n",
    "                else:\n",
    "                    if target == 'vulnerabilities':\n",
    "                        vulnList = content.get('vulnerabilities')\n",
    "                        path = content.get('displayTargetFile')\n",
    "                        print(\"Snyk path: {}\".format(path))\n",
    "                        if test_package.search(path) is not None:\n",
    "                            print(\"Snyk: Skipping:\" + path)\n",
    "                            continue\n",
    "                        elif benchmark_package.search(path) is not None:\n",
    "                            print(\"Snyk: Skipping:\" + path)\n",
    "                            continue\n",
    "                        elif examples_package.search(path) is not None:\n",
    "                            print(\"Snyk: Skipping:\" + path)\n",
    "                            continue\n",
    "                        elif testapplication_package.search(path) is not None:\n",
    "                            print(\"Snyk: Skipping:\" + path)\n",
    "                            continue\n",
    "                        else:\n",
    "                            for vuln in vulnList:\n",
    "                                directory = os.path.dirname(path)\n",
    "                                vulnerabilities_by_directory[directory].append(vuln)\n",
    "    return vulnerabilities_by_directory\n",
    "\n",
    "# Save vulnerabilities by directory\n",
    "def save_vulnerabilities_by_directory(vulnerabilities_by_directory, tool, base_dir):\n",
    "    for directory, vulnerabilities in vulnerabilities_by_directory.items():\n",
    "        clean_directory = re.sub(r'[^a-zA-Z0-9_\\-]', '', directory)\n",
    "        dir_path = os.path.join(base_dir, clean_directory)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        filename = f\"{tool}\"\n",
    "        filepath = os.path.join(dir_path, filename)\n",
    "        with open(filepath, 'w') as json_file:\n",
    "            json.dump(vulnerabilities, json_file, separators=(',', ':'))\n",
    "\n",
    "# Dump scan results into a JSON file\n",
    "def dump_scan_results(rics, sca_tools):\n",
    "    # Initialize the dictionary to store scan results\n",
    "    scan_results = {ric: {} for ric in rics}\n",
    "    onos_repos = []\n",
    "    osc_repos = []\n",
    "\n",
    "    # Gather repository names within each RIC directory\n",
    "    for ric in rics:\n",
    "        ric_dir = f\"./{ric}\"\n",
    "        if not os.path.exists(ric_dir):\n",
    "            os.makedirs(ric_dir)\n",
    "        for repository in sorted(os.listdir(ric_dir)):\n",
    "            if ric == \"ONOS\":\n",
    "                onos_repos.append(repository)\n",
    "            elif ric == \"OSC\":\n",
    "                osc_repos.append(repository)\n",
    "\n",
    "    # Initialize the scan_results dictionary with repositories\n",
    "    for ric in rics:\n",
    "        if ric == \"ONOS\":\n",
    "            scan_results[ric] = {repo: {} for repo in onos_repos}\n",
    "        elif ric == \"OSC\":\n",
    "            scan_results[ric] = {repo: {} for repo in osc_repos}\n",
    "\n",
    "        # Populate scan_results with SCA tool results\n",
    "        for repository in scan_results[ric].keys():\n",
    "            path_to_repository = os.path.join(f\"./{ric}\", repository)\n",
    "            for sca_tool_file in sorted(os.listdir(path_to_repository)):\n",
    "                if sca_tool_file in sca_tools:\n",
    "                    sca_tool_file_path = os.path.join(path_to_repository, sca_tool_file)\n",
    "                    with open(sca_tool_file_path) as file:\n",
    "                        vuln = file.read()\n",
    "                    scan_results[ric][repository][sca_tool_file] = vuln\n",
    "\n",
    "    # Save scan_results to a JSON file\n",
    "    with open('sca_results.json', 'w') as file:\n",
    "        json.dump(scan_results, file)\n",
    "\n",
    "    print(\"Finished writing: 'sca_results.json'\")\n",
    "    return scan_results\n",
    "\n",
    "# Extract CVEs and CVSS dependencies from the scan results\n",
    "def get_cves_cvss_dependencies(sca_tool, sca_tool_data):\n",
    "    cves_cvss_dependencies = []\n",
    "    cves = []\n",
    "    cvss = []\n",
    "    packages = []\n",
    "    if sca_tool == \"Grype.txt\":\n",
    "        for vulnerability in sca_tool_data:\n",
    "            if vulnerability.get(\"vulnerability\").get(\"id\") not in cves:\n",
    "                cves.append(vulnerability.get(\"vulnerability\").get(\"id\"))\n",
    "                cvss_info = vulnerability.get(\"vulnerability\").get(\"cvss\")\n",
    "                if cvss_info and len(cvss_info) > 0:\n",
    "                    cvss.append(cvss_info[0].get(\"metrics\").get(\"baseScore\"))\n",
    "                else:\n",
    "                    cvss.append(None)\n",
    "                    print(f\"Vulnerability without CVSS: {vulnerability.get('vulnerability').get('id')}\")\n",
    "                vulnerability_match_details = vulnerability.get(\"matchDetails\")\n",
    "                for match_detail in vulnerability_match_details:\n",
    "                    if \"package\" in match_detail[\"searchedBy\"].keys():\n",
    "                        packages.append(match_detail[\"searchedBy\"][\"package\"][\"name\"])\n",
    "                    elif \"Package\" in match_detail[\"searchedBy\"].keys():\n",
    "                        packages.append(match_detail[\"searchedBy\"][\"Package\"][\"name\"])\n",
    "            else:\n",
    "                continue\n",
    "        cves_cvss_dependencies = [cves, cvss, packages]\n",
    "        return cves_cvss_dependencies\n",
    "    elif sca_tool == \"Snyk.txt\":\n",
    "        for vulnerability in sca_tool_data:\n",
    "            if len(vulnerability.get(\"identifiers\").get(\"CVE\")) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                if vulnerability.get(\"identifiers\").get(\"CVE\")[0] not in cves:\n",
    "                    cves.append(vulnerability.get(\"identifiers\").get(\"CVE\")[0])\n",
    "                    cvss.append(vulnerability.get(\"cvssScore\"))\n",
    "                    packages.append(vulnerability.get(\"moduleName\"))\n",
    "        cves_cvss_dependencies = [cves, cvss, packages]\n",
    "        return cves_cvss_dependencies\n",
    "    elif sca_tool == \"Trivy.txt\":\n",
    "        for vulnerability in sca_tool_data:\n",
    "            if vulnerability.get(\"VulnerabilityID\") not in cves:\n",
    "                if vulnerability.get(\"CVSS\") is not None:\n",
    "                    cves.append(vulnerability.get(\"VulnerabilityID\"))\n",
    "                    packages.append(vulnerability.get(\"PkgName\"))\n",
    "                    nvd = vulnerability.get(\"CVSS\").get(\"nvd\")\n",
    "                    ghsa = vulnerability.get(\"CVSS\").get(\"ghsa\")\n",
    "                    if nvd is not None:\n",
    "                        cvss.append(nvd.get(\"V3Score\"))\n",
    "                        continue\n",
    "                    elif ghsa is not None:\n",
    "                        cvss.append(ghsa.get(\"V3Score\"))\n",
    "                        continue\n",
    "                else:\n",
    "                    print(f\"Vulnerability without CVSS: {vulnerability.get('VulnerabilityID')}\")\n",
    "                    continue\n",
    "        cves_cvss_dependencies = [cves, cvss, packages]\n",
    "        return cves_cvss_dependencies\n",
    "    else:\n",
    "        print(\"Unknown tool\")\n",
    "    return cves_cvss_dependencies\n",
    "\n",
    "# Extract CVEs from the scan results\n",
    "def extract_cves(sca_results):\n",
    "    # Initialize the dictionary to store CVE and CVSS dependencies\n",
    "    sca_cvecvss_dependencies = dict.fromkeys(sca_results.keys())\n",
    "    \n",
    "    print(\"Finished reading the SCA results data.\")\n",
    "    \n",
    "    for ric in sca_results.keys():\n",
    "        # Create repos as keys\n",
    "        sca_cvecvss_dependencies[ric] = dict.fromkeys(sca_results[ric].keys())\n",
    "        for repository in sca_results[ric].keys():\n",
    "            sca_cvecvss_dependencies[ric][repository] = dict.fromkeys(sca_results[ric][repository].keys())\n",
    "            print(repository)\n",
    "            for sca_tool in sca_results[ric][repository].keys():\n",
    "                sca_tool_data_str = sca_results[ric][repository][sca_tool]\n",
    "                if sca_tool_data_str is not None:  # Check if the data is not None\n",
    "                    try:\n",
    "                        sca_tool_data = json.loads(sca_tool_data_str)\n",
    "                        sca_cvecvss_dependencies[ric][repository][sca_tool] = get_cves_cvss_dependencies(sca_tool, sca_tool_data)\n",
    "                        if len(sca_cvecvss_dependencies[ric][repository][sca_tool][0]) != len(sca_cvecvss_dependencies[ric][repository][sca_tool][1]):\n",
    "                            print(\"More CVSS than CVE\")\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON for RIC: {ric}, Repository: {repository}, SCA_Tool: {sca_tool}\")\n",
    "                else:\n",
    "                    print(f\"NoneType found for RIC: {ric}, Repository: {repository}, SCA_Tool: {sca_tool}\")\n",
    "                    print(f\"sca_tool_data_str: {sca_tool_data_str}\")\n",
    "    return sca_cvecvss_dependencies\n",
    "\n",
    "# Count CVEs per repository and RIC\n",
    "def count_cves(cve_data):\n",
    "    print(\"Going to count CVEs per repo and per RIC\")\n",
    "\n",
    "    # Initialize the dictionary to store CVE counts per RIC\n",
    "    ric_cves = dict.fromkeys(cve_data.keys())\n",
    "\n",
    "    for ric in cve_data.keys():\n",
    "        total_ric_cves = []\n",
    "        for repository in cve_data[ric].keys():\n",
    "            total_repo_cves = []\n",
    "            for sca_tool in cve_data[ric][repository].keys():\n",
    "                if cve_data[ric][repository][sca_tool] is None or cve_data[ric][repository][sca_tool][0] is None:\n",
    "                    print(f\"NoneType found for RIC: {ric}, Repository: {repository}, SCA_Tool: {sca_tool}\")\n",
    "                    total_cve_count = 0\n",
    "                else:\n",
    "                    try:\n",
    "                        total_cve_count = len(cve_data[ric][repository][sca_tool][0])\n",
    "                    except TypeError as e:\n",
    "                        print(f\"NoneType found for RIC: {ric}, Repository: {repository}, SCA_Tool: {sca_tool}\")\n",
    "                        print(f\"Exception: {e}\")\n",
    "                        total_cve_count = 0\n",
    "                \n",
    "                if cve_data[ric][repository][sca_tool] is not None and cve_data[ric][repository][sca_tool][0] is not None:\n",
    "                    for cve in cve_data[ric][repository][sca_tool][0]:\n",
    "                        if cve not in total_repo_cves:\n",
    "                            total_repo_cves.append(cve)\n",
    "            \n",
    "            print(\"RIC: {}, Repository: {}, Total Repo CVEs: {}\".format(ric, repository, len(total_repo_cves)))\n",
    "            total_ric_cves.extend(total_repo_cves)\n",
    "        \n",
    "        ric_cves[ric] = total_ric_cves\n",
    "    \n",
    "    pprint.pprint(ric_cves)\n",
    "    for ric in ric_cves.keys():\n",
    "        print(\"RIC: {}, Total unique CVEs: {}\".format(ric, len(ric_cves[ric])))\n",
    "\n",
    "# Count CVEs per repository and tool\n",
    "def per_repo_cve_count(cve_data):\n",
    "    print(\"1. CVEs per RIC/repo/tool\\n\"\n",
    "          \"2. Total CVEs per RIC/repo with duplicates\\n\"\n",
    "          \"3. Total CVEs per RIC/repo without duplicates\")\n",
    "    \n",
    "    # First CVEs per RIC/repo/tool\n",
    "    cve_per_ric_repo_tool = dict.fromkeys(rics)\n",
    "    for ric in cve_data.keys():\n",
    "        cve_per_ric_repo_tool[ric] = dict.fromkeys(cve_data[ric].keys())\n",
    "        for repository in cve_data[ric].keys():\n",
    "            cve_per_ric_repo_tool[ric][repository] = dict.fromkeys(cve_data[ric][repository].keys())\n",
    "            for sca_tool in cve_data[ric][repository].keys():\n",
    "                if cve_data[ric][repository][sca_tool] is None:\n",
    "                        cve_per_ric_repo_tool[ric][repository][sca_tool] = 0\n",
    "                else:\n",
    "                        try:\n",
    "                            cve_per_ric_repo_tool[ric][repository][sca_tool] = len(cve_data[ric][repository][sca_tool][0])\n",
    "                        except TypeError as e:\n",
    "                            print(f\"NoneType found for RIC: {ric}, Repository: {repository}, SCA_Tool: {sca_tool}\")\n",
    "                            print(f\"Exception: {e}\")\n",
    "                            cve_per_ric_repo_tool[ric][repository][sca_tool] = 0\n",
    "\n",
    "    # Combine the CVEs from all the tools and save two lists with duplicates and without duplicates\n",
    "    cve_per_ric_repo = dict.fromkeys(rics)\n",
    "    for ric in cve_data.keys():\n",
    "        cve_per_ric_repo[ric] = dict.fromkeys(cve_data[ric].keys())\n",
    "        for repository in cve_data[ric].keys():\n",
    "            cve_list_with_dups = []\n",
    "            cve_list_without_dups = []\n",
    "            for sca_tool in cve_data[ric][repository].keys():  \n",
    "                try:\n",
    "                    for cve in cve_data[ric][repository][sca_tool][0]:\n",
    "                        cve_list_with_dups.append(cve)\n",
    "                        if cve not in cve_list_without_dups:\n",
    "                            cve_list_without_dups.append(cve)\n",
    "                except TypeError as e:\n",
    "                    print(f\"NoneType found for RIC: {ric}, Repository: {repository}, SCA_Tool: {sca_tool}\")\n",
    "                    print(f\"Exception: {e}\")\n",
    "            cve_per_ric_repo[ric][repository] = [cve_list_with_dups, cve_list_without_dups]\n",
    "    return cve_per_ric_repo_tool, cve_per_ric_repo\n",
    "\n",
    "# Analyze the distribution of CVSS scores\n",
    "def cvss_distribution(cvss_data):\n",
    "    for ric in cvss_data.keys():\n",
    "        total_cve_count = 0\n",
    "        total_cvss_count = 0\n",
    "        for repository in cvss_data[ric].keys():\n",
    "            for sca_tool in cvss_data[ric][repository].keys():\n",
    "                if cvss_data[ric][repository][sca_tool] is not None:\n",
    "                    total_cve_count += len(cvss_data[ric][repository][sca_tool][0])\n",
    "                    total_cvss_count += len(cvss_data[ric][repository][sca_tool][1])\n",
    "\n",
    "    # Initialize dictionaries for CVSS distribution\n",
    "    low_cvss_per_ric_repo = dict.fromkeys(cvss_data.keys())\n",
    "    medium_cvss_per_ric_repo = dict.fromkeys(cvss_data.keys())\n",
    "    high_cvss_per_ric_repo = dict.fromkeys(cvss_data.keys())\n",
    "    critical_cvss_per_ric_repo = dict.fromkeys(cvss_data.keys())\n",
    "    cve_per_ric_repo = dict.fromkeys(cvss_data.keys())\n",
    "    none_counter = 0\n",
    "    \n",
    "    for ric in cvss_data.keys():\n",
    "        low_cvss_per_ric_repo[ric] = dict.fromkeys(cvss_data[ric].keys())\n",
    "        medium_cvss_per_ric_repo[ric] = dict.fromkeys(cvss_data[ric].keys())\n",
    "        high_cvss_per_ric_repo[ric] = dict.fromkeys(cvss_data[ric].keys())\n",
    "        critical_cvss_per_ric_repo[ric] = dict.fromkeys(cvss_data[ric].keys())\n",
    "        cve_per_ric_repo[ric] = dict.fromkeys(cvss_data[ric].keys())\n",
    "        \n",
    "        for repository in cvss_data[ric].keys():\n",
    "            low_cvss_per_ric_repo[ric][repository] = dict.fromkeys(cvss_data[ric][repository].keys())\n",
    "            medium_cvss_per_ric_repo[ric][repository] = dict.fromkeys(cvss_data[ric][repository].keys())\n",
    "            high_cvss_per_ric_repo[ric][repository] = dict.fromkeys(cvss_data[ric][repository].keys())\n",
    "            critical_cvss_per_ric_repo[ric][repository] = dict.fromkeys(cvss_data[ric][repository].keys())\n",
    "            cve_per_ric_repo[ric][repository] = dict.fromkeys(cvss_data[ric][repository].keys())\n",
    "            \n",
    "            low_cves = []\n",
    "            medium_cves = []\n",
    "            high_cves = []\n",
    "            critical_cves = []\n",
    "            cves = []\n",
    "            \n",
    "            for sca_tool in cvss_data[ric][repository].keys():\n",
    "                if cvss_data[ric][repository][sca_tool] is not None and sca_tool != \"Scantist.json\":\n",
    "                    for index, cvss in enumerate(cvss_data[ric][repository][sca_tool][1]):\n",
    "                        cve = cvss_data[ric][repository][sca_tool][0][index]\n",
    "                        if cvss is None:\n",
    "                            none_counter += 1\n",
    "                        elif 0.1 <= cvss <= 3.9:\n",
    "                            if cve not in low_cves and cve not in medium_cves and cve not in high_cves and cve not in critical_cves:\n",
    "                                low_cves.append(cve)\n",
    "                            if cve not in cves:\n",
    "                                cves.append(cve)\n",
    "                        elif 4.0 <= cvss <= 6.9:\n",
    "                            if cve not in low_cves and cve not in medium_cves and cve not in high_cves and cve not in critical_cves:\n",
    "                                medium_cves.append(cve)\n",
    "                            if cve not in cves:\n",
    "                                cves.append(cve)\n",
    "                        elif 7.0 <= cvss <= 8.9:\n",
    "                            if cve not in low_cves and cve not in medium_cves and cve not in high_cves and cve not in critical_cves:\n",
    "                                high_cves.append(cve)\n",
    "                            if cve not in cves:\n",
    "                                cves.append(cve)\n",
    "                        elif 9.0 <= cvss <= 10.0:\n",
    "                            if cve not in low_cves and cve not in medium_cves and cve not in high_cves and cve not in critical_cves:\n",
    "                                critical_cves.append(cve)\n",
    "                            if cve not in cves:\n",
    "                                cves.append(cve)\n",
    "            \n",
    "            low_cvss_per_ric_repo[ric][repository] = [len(low_cves), low_cves]\n",
    "            medium_cvss_per_ric_repo[ric][repository] = [len(medium_cves), medium_cves]\n",
    "            high_cvss_per_ric_repo[ric][repository] = [len(high_cves), high_cves]\n",
    "            critical_cvss_per_ric_repo[ric][repository] = [len(critical_cves), critical_cves]\n",
    "            cve_per_ric_repo[ric][repository] = [len(cves), cves]\n",
    "            total = len(low_cves) + len(medium_cves) + len(high_cves) + len(critical_cves)\n",
    "    \n",
    "    print(\"Nonecounter: \" + str(none_counter))\n",
    "    \n",
    "    return low_cvss_per_ric_repo, medium_cvss_per_ric_repo, high_cvss_per_ric_repo, critical_cvss_per_ric_repo, cve_per_ric_repo, total\n",
    "\n",
    "# Analyze package distribution\n",
    "def package_distribution_analysis(cvss_data):\n",
    "    print(\"Analyzing package distribution...\")\n",
    "\n",
    "    # Initialize dictionaries for package distribution\n",
    "    packages_per_ric_repo = dict.fromkeys(cvss_data.keys())\n",
    "    packages_per_ric = dict.fromkeys(cvss_data.keys())\n",
    "    \n",
    "    for ric in cvss_data.keys():\n",
    "        packages_per_ric_repo[ric] = dict.fromkeys(cvss_data[ric].keys())\n",
    "        ric_packages = []\n",
    "        \n",
    "        for repository in cvss_data[ric].keys():\n",
    "            packages_per_ric_repo[ric][repository] = dict.fromkeys(cvss_data[ric][repository].keys())\n",
    "            packages = []\n",
    "            unique_packages = []\n",
    "            \n",
    "            for sca_tool in cvss_data[ric][repository].keys():\n",
    "                if cvss_data[ric][repository][sca_tool] is not None and sca_tool != \"Scantist.json\":  # Check if data is not None and tool is not \"Scantist.json\"\n",
    "                    for path in cvss_data[ric][repository][sca_tool][2]:\n",
    "                        packages.append(path)\n",
    "                        ric_packages.append(path)\n",
    "                        if path not in unique_packages:\n",
    "                            unique_packages.append(path)\n",
    "            \n",
    "            packages_per_ric_repo[ric][repository] = [{\"unique_packages\": len(unique_packages)}, dict(Counter(packages))]\n",
    "        \n",
    "        packages_per_ric[ric] = dict(Counter(ric_packages))\n",
    "    \n",
    "    return packages_per_ric_repo, packages_per_ric\n",
    "\n",
    "# Count total CVEs per RIC\n",
    "def count_total_cves(low, medium, high, critical):\n",
    "    total_cves = {ric: sum(len(low[ric][repo][1]) + len(medium[ric][repo][1]) + len(high[ric][repo][1]) + len(critical[ric][repo][1]) for repo in low[ric].keys()) for ric in low.keys()}\n",
    "    return total_cves\n",
    "\n",
    "# Tabulate CVSS scores per RIC\n",
    "def tabulate_cvss(low_cve_data, medium_cve_data, high_cve_data, critical_cve_data):\n",
    "    for ric in low_cve_data.keys():\n",
    "        low_cve_count = 0\n",
    "        medium_cve_count = 0\n",
    "        high_cve_count = 0\n",
    "        critical_cve_count = 0\n",
    "        for repository in low_cve_data[ric]:\n",
    "            if low_cve_data[ric][repository] is not None:\n",
    "                low_cve_count += low_cve_data[ric][repository][0]\n",
    "        for repository in medium_cve_data[ric]:\n",
    "            if medium_cve_data[ric][repository] is not None:\n",
    "                medium_cve_count += medium_cve_data[ric][repository][0]\n",
    "        for repository in high_cve_data[ric]:\n",
    "            if high_cve_data[ric][repository] is not None:\n",
    "                high_cve_count += high_cve_data[ric][repository][0]\n",
    "        for repository in critical_cve_data[ric]:\n",
    "            if critical_cve_data[ric][repository] is not None:\n",
    "                critical_cve_count += critical_cve_data[ric][repository][0]\n",
    "        print(\"RIC: \" + str(ric) + \" TOTAL Low CVEs: \" + str(low_cve_count))\n",
    "        print(\"RIC: \" + str(ric) + \" TOTAL Medium CVEs: \" + str(medium_cve_count))\n",
    "        print(\"RIC: \" + str(ric) + \" TOTAL High CVEs: \" + str(high_cve_count))\n",
    "        print(\"RIC: \" + str(ric) + \" TOTAL Critical CVEs: \" + str(critical_cve_count))\n",
    "\n",
    "def main(data_file, tool, ric):\n",
    "\n",
    "    # Load the data file\n",
    "    with open(data_file, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    # Format the data using the appropriate SCA tool\n",
    "    formatted_data = format_sca_tool_data(data, tool)\n",
    "\n",
    "    # Get vulnerabilities by directory\n",
    "    vulnerabilities_by_directory = get_vulnerabilities_by_directory(data, tool)\n",
    "\n",
    "    # Save vulnerabilities by directory\n",
    "    base_dir = f\"./{ric}\"\n",
    "    save_vulnerabilities_by_directory(vulnerabilities_by_directory, tool, base_dir)\n",
    "\n",
    "    # Dump scan results\n",
    "    sca_results = dump_scan_results([ric], [tool])\n",
    "    sca_cvecvss_dependencies_results = extract_cves(sca_results)\n",
    "\n",
    "    # Count CVEs\n",
    "    count_cves(sca_cvecvss_dependencies_results)\n",
    "\n",
    "    # Get per repo CVE count\n",
    "    cve_per_ric_repo_tool, cve_per_ric_repo = per_repo_cve_count(sca_cvecvss_dependencies_results)\n",
    "\n",
    "    # Get CVSS distribution\n",
    "    low_cvss_per_ric_repo, medium_cvss_per_ric_repo, high_cvss_per_ric_repo, critical_cvss_per_ric_repo, cve_per_ric_repo, total_vulnerabilities_ric = cvss_distribution(sca_cvecvss_dependencies_results)\n",
    "\n",
    "    # Analyze package distribution\n",
    "    packages_per_ric_repo, packages_per_ric = package_distribution_analysis(sca_cvecvss_dependencies_results)\n",
    "\n",
    "    # Tabulate CVSS\n",
    "    tabulate_cvss(low_cvss_per_ric_repo, medium_cvss_per_ric_repo, high_cvss_per_ric_repo, critical_cvss_per_ric_repo)\n",
    "\n",
    "    # Calculate total vulnerabilities per RIC\n",
    "    total_vulnerabilities_ric = total_cve_count\n",
    "    \n",
    "    # Calculate vulnerabilities per repository\n",
    "    vulnerabilities_per_repo = {ric: {repo: len(cves_without_dups) for repo, (_, cves_without_dups) in repos.items()} for ric, repos in cve_per_ric_repo.items()}\n",
    "\n",
    "    # Calculate severity distribution\n",
    "    severity_distribution = {\n",
    "        ric: {\n",
    "            'low': sum(len(low_cvss_per_ric_repo[ric][repo][1]) for repo in repos.keys()),\n",
    "            'medium': sum(len(medium_cvss_per_ric_repo[ric][repo][1]) for repo in repos.keys()),\n",
    "            'high': sum(len(high_cvss_per_ric_repo[ric][repo][1]) for repo in repos.keys()),\n",
    "            'critical': sum(len(critical_cvss_per_ric_repo[ric][repo][1]) for repo in repos.keys())\n",
    "        }\n",
    "        for ric, repos in sca_cvecvss_dependencies_results.items()\n",
    "    }\n",
    "\n",
    "    # Calculate vulnerable packages per RIC\n",
    "    vulnerable_packages_per_ric = {ric: len(packages) for ric, packages in packages_per_ric.items()}\n",
    "\n",
    "    # Calculate vulnerable packages per repository\n",
    "    vulnerable_packages_per_repo = {ric: {repo: packages_info[0]['unique_packages'] for repo, packages_info in repos.items()} for ric, repos in packages_per_ric_repo.items()}\n",
    "\n",
    "        \n",
    "    # Remove the .txt extension from the tool name\n",
    "    tool_name = tool.split('.')[0]\n",
    "    \n",
    "    # Define a color-blind friendly palette\n",
    "    color_blind_friendly_palette = {\n",
    "    'blue': '#0072B2',\n",
    "    'orange': '#D55E00',\n",
    "    'green': '#009E73',\n",
    "    'yellow': '#F0E442',\n",
    "    'red': '#CC79A7',\n",
    "    'purple': '#CC79A7',\n",
    "    'cyan': '#56B4E9',\n",
    "    'grey': '#999999'\n",
    "    }\n",
    "    \n",
    "    tool_name = tool.split('.')[0]\n",
    "\n",
    "    # Plotting with adjusted figure size and bar width\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    plt.bar([ric], [total_vulnerabilities_ric], color=color_blind_friendly_palette['blue'], width=0.5)\n",
    "    plt.title(f'Total Number of Vulnerabilities per RIC (Tool: {tool_name})')\n",
    "    plt.xlabel('RIC')\n",
    "    plt.ylabel('Number of Vulnerabilities')\n",
    "    plt.ylim(0, total_vulnerabilities_ric + 5)  # Adjust y-axis limit to fit the data\n",
    "    plt.grid(axis='y')\n",
    "    plt.savefig(f'total_vulnerabilities_per_ric_{tool_name}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    for ric, repos in vulnerabilities_per_repo.items():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(repos.keys(), repos.values(), color=color_blind_friendly_palette['green'], width=0.5)\n",
    "        plt.title(f'Vulnerabilities per Repository for {ric} (Tool: {tool_name})')\n",
    "        plt.xlabel('Repository')\n",
    "        plt.ylabel('Number of Vulnerabilities')\n",
    "        plt.ylim(0, max(repos.values()) + 5)  # Adjust y-axis limit to fit the data\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.grid(axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'vulnerabilities_per_repo_{ric}_{tool_name}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    for ric, severity in severity_distribution.items():\n",
    "        plt.figure(figsize=(8, 4.5))\n",
    "        colors = [color_blind_friendly_palette['green'],color_blind_friendly_palette['blue'], color_blind_friendly_palette['orange'],  color_blind_friendly_palette['red']]\n",
    "        plt.bar(severity.keys(), severity.values(), color=colors, width=0.5)\n",
    "        plt.title(f'Severity Distribution for {ric} (Tool: {tool_name})')\n",
    "        plt.xlabel('Severity')\n",
    "        plt.ylabel('Number of Vulnerabilities')\n",
    "        plt.ylim(0, max(severity.values()) + 5)  # Adjust y-axis limit to fit the data\n",
    "        plt.grid(axis='y')\n",
    "        plt.savefig(f'severity_distribution_{ric}_{tool_name}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    plt.figure(figsize=(3, 5))\n",
    "    plt.bar(vulnerable_packages_per_ric.keys(), vulnerable_packages_per_ric.values(), color=color_blind_friendly_palette['yellow'], width=0.5)\n",
    "    plt.title(f'Distribution of Vulnerable Dependency Packages per RIC (Tool: {tool_name})')\n",
    "    plt.xlabel('RIC')\n",
    "    plt.ylabel('Number of Vulnerable Packages')\n",
    "    plt.ylim(0, max(vulnerable_packages_per_ric.values()) + 5)  # Adjust y-axis limit to fit the data\n",
    "    plt.grid(axis='y')\n",
    "    plt.savefig(f'vulnerable_packages_per_ric_{tool_name}.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    for ric, repos in vulnerable_packages_per_repo.items():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(repos.keys(), repos.values(), color=color_blind_friendly_palette['purple'], width=0.5)\n",
    "        plt.title(f'Vulnerable Dependency Packages per Repository for {ric} (Tool: {tool_name})')\n",
    "        plt.xlabel('Repository')\n",
    "        plt.ylabel('Number of Vulnerable Packages')\n",
    "        plt.ylim(0, max(repos.values()) + 5)  # Adjust y-axis limit to fit the data\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.grid(axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'vulnerable_packages_per_repo_{ric}_{tool_name}.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main(\"snyk_results-9.json\", \"Snyk.txt\", \"ONOS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
